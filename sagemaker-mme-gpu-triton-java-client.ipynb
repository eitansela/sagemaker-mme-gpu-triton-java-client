{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9965651d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run Multiple Models on the Same GPU with Amazon SageMaker Multi-Model Endpoints Powered by NVIDIA Triton Inference Server\n",
    "\n",
    "This notebook was run on a `ml.g4dn.xlarge` SageMaker Notebook instance type, with `conda_pytorch_p38` kernel.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Install the necessary Python modules to use and interact with [NVIDIA Triton Inference Server](https://github.com/triton-inference-server/server/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f99f78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! pip install torch==1.10.0 sagemaker transformers==4.9.1 tritonclient[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51afb5e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b85f17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import boto3\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import tritonclient.http as http_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c14c3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sm_client = session.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72b300",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "account_id_map = {\n",
    "    \"us-east-1\": \"785573368785\",\n",
    "    \"us-east-2\": \"007439368137\",\n",
    "    \"us-west-1\": \"710691900526\",\n",
    "    \"us-west-2\": \"301217895009\",\n",
    "    \"eu-west-1\": \"802834080501\",\n",
    "    \"eu-west-2\": \"205493899709\",\n",
    "    \"eu-west-3\": \"254080097072\",\n",
    "    \"eu-north-1\": \"601324751636\",\n",
    "    \"eu-south-1\": \"966458181534\",\n",
    "    \"eu-central-1\": \"746233611703\",\n",
    "    \"ap-east-1\": \"110948597952\",\n",
    "    \"ap-south-1\": \"763008648453\",\n",
    "    \"ap-northeast-1\": \"941853720454\",\n",
    "    \"ap-northeast-2\": \"151534178276\",\n",
    "    \"ap-southeast-1\": \"324986816169\",\n",
    "    \"ap-southeast-2\": \"355873309152\",\n",
    "    \"cn-northwest-1\": \"474822919863\",\n",
    "    \"cn-north-1\": \"472730292857\",\n",
    "    \"sa-east-1\": \"756306329178\",\n",
    "    \"ca-central-1\": \"464438896020\",\n",
    "    \"me-south-1\": \"836785723513\",\n",
    "    \"af-south-1\": \"774647643957\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c40262",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c27284",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 2 - Save Model and tokenizer\n",
    "\n",
    "We now save the tokenizer and the model to folders within the model repository\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "* `model_name`: Model identifier from the Hugging Face model hub library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227aa25d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "tokenizer.save_pretrained('model_repo/e2e/tokenizer')\n",
    "model.save_pretrained('model_repo/e2e/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbe6cf0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 3 - Run Local Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad5e07",
   "metadata": {},
   "source": [
    "> **WARNING**: The cells under part 3 will only work if run within a SageMaker Notebook Instance!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b930a2e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "The following cells run the Triton Inference Server container in the background and load all the models within the folder `/model_repo`. The docker won't fail if one or more of the model fails because of `--exit-on-error=false`, which is useful for iterative code and model repository building. Remove `-d` to see the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028adfaf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!sudo docker system prune -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba308c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!docker run --gpus=all -d --shm-size=4G --rm -p8000:8000 -p8001:8001 -p8002:8002 -v$(pwd)/model_repo:/model_repository nvcr.io/nvidia/tritonserver:22.09-py3 tritonserver --model-repository=/model_repository --exit-on-error=false --strict-model-config=false\n",
    "# time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f26c7e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CONTAINER_ID=!docker container ls -q\n",
    "FIRST_CONTAINER_ID = CONTAINER_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df66406e",
   "metadata": {},
   "source": [
    "Uncomment the next cell and run it to view the container logs and understand Triton model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e90a61",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !docker logs $FIRST_CONTAINER_ID -f\n",
    "!docker logs $FIRST_CONTAINER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282f009",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test TensorRT model by invoking the local Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caeff3e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start a local Triton client\n",
    "try:\n",
    "    triton_client = http_client.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e16413",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create inputs to send to Triton\n",
    "model_name = \"e2e\"\n",
    "\n",
    "text_inputs = [\"Sentence 1\", \"Sentence 2\"]\n",
    "\n",
    "# Text is passed to Trtion as BYTES\n",
    "inputs = []\n",
    "inputs.append(http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\"))\n",
    "\n",
    "# We need to structure batch inputs as such\n",
    "batch_request = [[text_inputs[i]] for i in range(len(text_inputs))]\n",
    "input0_real = np.array(batch_request, dtype=np.object_)\n",
    "\n",
    "inputs[0].set_data_from_numpy(input0_real, binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6147614e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "outputs.append(http_client.InferRequestedOutput(\"SENT_EMBED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eda8bf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = triton_client.infer(model_name=model_name, inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe918ab3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs0 = results.as_numpy(\"SENT_EMBED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea239042",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, output in enumerate(outputs0):\n",
    "    print(text_inputs[idx])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc5887",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use this to stop the container that was started in detached mode\n",
    "!docker kill $FIRST_CONTAINER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24ac12",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4440d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 4 - Deploy Triton to SageMaker MME Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc7dd64",
   "metadata": {},
   "source": [
    "# MME Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9361e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if region not in account_id_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.09-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")\n",
    "\n",
    "triton_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38215d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82071233",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C model_repo/ -czf e2e.tar.gz e2e\n",
    "prefix = 'bert_mme_gpu'\n",
    "e2e_uri = sagemaker_session.upload_data(path=\"e2e.tar.gz\", key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103cccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "!aws s3 ls $model_data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a043bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "\n",
    "container = {\n",
    "    \"Image\": triton_image_uri,\n",
    "    \"ModelDataUrl\": model_data_url,\n",
    "    \"Mode\": \"MultiModel\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05444d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0814589",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae3400",
   "metadata": {},
   "source": [
    "## Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ad727",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979eb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = [\"Sentence 1\", \"Sentence 2\"]\n",
    "\n",
    "inputs = []\n",
    "inputs.append(http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\"))\n",
    "\n",
    "batch_request = [[text_inputs[i]] for i in range(len(text_inputs))]\n",
    "\n",
    "input0_real = np.array(batch_request, dtype=np.object_)\n",
    "\n",
    "inputs[0].set_data_from_numpy(input0_real, binary_data=False)\n",
    "\n",
    "len(input0_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "outputs.append(http_client.InferRequestedOutput(\"SENT_EMBED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2653571",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0cda4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "request_body, header_length = http_client.InferenceServerClient.generate_request_body(\n",
    "    inputs, outputs=outputs\n",
    ")\n",
    "\n",
    "print(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    # ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "        # header_length\n",
    "    # ),\n",
    "    ContentType='application/octet-stream',\n",
    "    Body=request_body,\n",
    "    TargetModel='e2e.tar.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f87ee7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "\n",
    "# Read response body\n",
    "result = http_client.InferenceServerClient.parse_response_body(\n",
    "    response[\"Body\"].read(), header_length=int(header_length_str)\n",
    ")\n",
    "\n",
    "outputs_data = result.as_numpy(\"SENT_EMBED\")\n",
    "\n",
    "for idx, output in enumerate(outputs_data):\n",
    "    print(text_inputs[idx])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95f62e",
   "metadata": {},
   "source": [
    "# Part 5 - Test SageMaker Endpoint with Java Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3732ec",
   "metadata": {},
   "source": [
    "## Build Java App Docker Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a2c04b",
   "metadata": {},
   "source": [
    "Get credentials first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1691eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://169.254.169.254/latest/meta-data/iam/security-credentials/BaseNotebookInstanceEc2InstanceRole>tmp.json\n",
    "f = open('tmp.json')\n",
    "metadata=json.load(f)\n",
    "os.remove('tmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc414ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./java_client/credentials', 'a') as credentials_file:\n",
    "    credentials_file.write(\"[default]\\n\")\n",
    "    credentials_file.write(f\"aws_access_key_id = {metadata['AccessKeyId']}\\n\")\n",
    "    credentials_file.write(f\"aws_secret_access_key = {metadata['SecretAccessKey']}\\n\")\n",
    "    credentials_file.write(f\"aws_session_token = {metadata['Token']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4416d",
   "metadata": {},
   "source": [
    "### Build the Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build  -t sagemaker-runtime-java-example ./java_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63547eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('./java_client/credentials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e1b67",
   "metadata": {},
   "source": [
    "### Run the Docker Container to invoke the endpoint from Java Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -e AWS_REGION=us-east-1 -e ENDPOINT_NAME={endpoint_name} sagemaker-runtime-java-example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf0c81",
   "metadata": {},
   "source": [
    "# Part 6 - Delete the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4933eea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
