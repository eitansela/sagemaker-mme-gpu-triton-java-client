{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b413b693",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run Multiple Models on the Same GPU with Amazon SageMaker Multi-Model Endpoints Powered by NVIDIA Triton Inference Server\n",
    "\n",
    "This demos was run on a `ml.g4dn.xlarge` Notebook instance type, with `conda_pytorch_p38` kernel.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Install the necessary Python modules to use and interact with [NVIDIA Triton Inference Server](https://github.com/triton-inference-server/server/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43d600",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! pip install torch==1.10.0 sagemaker transformers==4.9.1 tritonclient[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317adb5e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed5a44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import boto3\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import tritonclient.http as http_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76f890",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sm_client = session.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d9e40",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "account_id_map = {\n",
    "    \"us-east-1\": \"785573368785\",\n",
    "    \"us-east-2\": \"007439368137\",\n",
    "    \"us-west-1\": \"710691900526\",\n",
    "    \"us-west-2\": \"301217895009\",\n",
    "    \"eu-west-1\": \"802834080501\",\n",
    "    \"eu-west-2\": \"205493899709\",\n",
    "    \"eu-west-3\": \"254080097072\",\n",
    "    \"eu-north-1\": \"601324751636\",\n",
    "    \"eu-south-1\": \"966458181534\",\n",
    "    \"eu-central-1\": \"746233611703\",\n",
    "    \"ap-east-1\": \"110948597952\",\n",
    "    \"ap-south-1\": \"763008648453\",\n",
    "    \"ap-northeast-1\": \"941853720454\",\n",
    "    \"ap-northeast-2\": \"151534178276\",\n",
    "    \"ap-southeast-1\": \"324986816169\",\n",
    "    \"ap-southeast-2\": \"355873309152\",\n",
    "    \"cn-northwest-1\": \"474822919863\",\n",
    "    \"cn-north-1\": \"472730292857\",\n",
    "    \"sa-east-1\": \"756306329178\",\n",
    "    \"ca-central-1\": \"464438896020\",\n",
    "    \"me-south-1\": \"836785723513\",\n",
    "    \"af-south-1\": \"774647643957\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c560f93",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ee44e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 2 - Save Model and tokenizer\n",
    "\n",
    "We now save the tokenizer and the model to folders within the model repository\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "* `model_name`: Model identifier from the Hugging Face model hub library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272efbb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "tokenizer.save_pretrained('model_repo/e2e/tokenizer')\n",
    "model.save_pretrained('model_repo/e2e/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96666833",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 3 - Run Local Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d995b",
   "metadata": {},
   "source": [
    "> **WARNING**: The cells under part 3 will only work if run within a SageMaker Notebook Instance!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4cbba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "The following cells run the Triton Inference Server container in the background and load all the models within the folder `/model_repo`. The docker won't fail if one or more of the model fails because of `--exit-on-error=false`, which is useful for iterative code and model repository building. Remove `-d` to see the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4526f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!sudo docker system prune -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2250631",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!docker run --gpus=all -d --shm-size=4G --rm -p8000:8000 -p8001:8001 -p8002:8002 -v$(pwd)/model_repo:/model_repository nvcr.io/nvidia/tritonserver:22.09-py3 tritonserver --model-repository=/model_repository --exit-on-error=false --strict-model-config=false\n",
    "# time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcf3a5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CONTAINER_ID=!docker container ls -q\n",
    "FIRST_CONTAINER_ID = CONTAINER_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81fcd9",
   "metadata": {},
   "source": [
    "Uncomment the next cell and run it to view the container logs and understand Triton model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68599bc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !docker logs $FIRST_CONTAINER_ID -f\n",
    "!docker logs $FIRST_CONTAINER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bc475",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test TensorRT model by invoking the local Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a0e80",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start a local Triton client\n",
    "try:\n",
    "    triton_client = http_client.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165783f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create inputs to send to Triton\n",
    "model_name = \"e2e\"\n",
    "\n",
    "text_inputs = [\"Sentence 1\", \"Sentence 2\"]\n",
    "\n",
    "# Text is passed to Trtion as BYTES\n",
    "inputs = []\n",
    "inputs.append(http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\"))\n",
    "\n",
    "# We need to structure batch inputs as such\n",
    "batch_request = [[text_inputs[i]] for i in range(len(text_inputs))]\n",
    "input0_real = np.array(batch_request, dtype=np.object_)\n",
    "\n",
    "inputs[0].set_data_from_numpy(input0_real, binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66504a8c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "outputs.append(http_client.InferRequestedOutput(\"SENT_EMBED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1545fb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = triton_client.infer(model_name=model_name, inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf78a0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs0 = results.as_numpy(\"SENT_EMBED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, output in enumerate(outputs0):\n",
    "    print(text_inputs[idx])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd80373",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use this to stop the container that was started in detached mode\n",
    "!docker kill $FIRST_CONTAINER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eabb45",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c265db",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 4 - Deploy Triton to SageMaker MME Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663159e",
   "metadata": {},
   "source": [
    "# MME Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if region not in account_id_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.09-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")\n",
    "\n",
    "triton_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981830dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a879c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C model_repo/ -czf e2e.tar.gz e2e\n",
    "prefix = 'bert_mme_gpu'\n",
    "e2e_uri = sagemaker_session.upload_data(path=\"e2e.tar.gz\", key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "!aws s3 ls $model_data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a999e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "\n",
    "container = {\n",
    "    \"Image\": triton_image_uri,\n",
    "    \"ModelDataUrl\": model_data_url,\n",
    "    \"Mode\": \"MultiModel\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b702d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec588f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090097b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b007e",
   "metadata": {},
   "source": [
    "## Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76796c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = [\"Sentence 1\", \"Sentence 2\"]\n",
    "\n",
    "inputs = []\n",
    "inputs.append(http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\"))\n",
    "\n",
    "batch_request = [[text_inputs[i]] for i in range(len(text_inputs))]\n",
    "\n",
    "input0_real = np.array(batch_request, dtype=np.object_)\n",
    "\n",
    "inputs[0].set_data_from_numpy(input0_real, binary_data=False)\n",
    "\n",
    "len(input0_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "outputs.append(http_client.InferRequestedOutput(\"SENT_EMBED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259b820",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "request_body, header_length = http_client.InferenceServerClient.generate_request_body(\n",
    "    inputs, outputs=outputs\n",
    ")\n",
    "\n",
    "print(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf46ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    # ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "        # header_length\n",
    "    # ),\n",
    "    ContentType='application/octet-stream',\n",
    "    Body=request_body,\n",
    "    TargetModel='e2e.tar.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_length_str,header_length_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4da13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"ContentType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82497af4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "\n",
    "# Read response body\n",
    "result = http_client.InferenceServerClient.parse_response_body(\n",
    "    response[\"Body\"].read(), header_length=int(header_length_str)\n",
    ")\n",
    "\n",
    "outputs_data = result.as_numpy(\"SENT_EMBED\")\n",
    "\n",
    "for idx, output in enumerate(outputs_data):\n",
    "    print(text_inputs[idx])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab067bd",
   "metadata": {},
   "source": [
    "# Part 5 - Test SageMaker Endpoint with Java Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085057fb",
   "metadata": {},
   "source": [
    "## Build Java App Docker Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65aa68e",
   "metadata": {},
   "source": [
    "Get credentials first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46082cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://169.254.169.254/latest/meta-data/iam/security-credentials/BaseNotebookInstanceEc2InstanceRole>tmp.json\n",
    "f = open('tmp.json')\n",
    "metadata=json.load(f)\n",
    "os.remove('tmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./java_client/credentials', 'a') as credentials_file:\n",
    "    credentials_file.write(\"[default]\\n\")\n",
    "    credentials_file.write(f\"aws_access_key_id = {metadata['AccessKeyId']}\\n\")\n",
    "    credentials_file.write(f\"aws_secret_access_key = {metadata['SecretAccessKey']}\\n\")\n",
    "    credentials_file.write(f\"aws_session_token = {metadata['Token']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ae921",
   "metadata": {},
   "source": [
    "### Build the Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9779cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build  -t sagemaker-runtime-java-example ./java_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7479c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('./java_client/credentials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf158bd1",
   "metadata": {},
   "source": [
    "### Run the Docker Container to invoke the endpoint from Java Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09850034",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -e AWS_REGION=us-east-1 -e ENDPOINT_NAME={endpoint_name} sagemaker-runtime-java-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648bcbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
